{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](exercise_5_8_1.png)\n",
    "![](exercise_5_8_2.png)\n",
    "![](off_policy_mc_control.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-350ec7629037>, line 98)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-350ec7629037>\"\u001b[0;36m, line \u001b[0;32m98\u001b[0m\n\u001b[0;31m    assert min(action) >= 0 && max(state[2], state[3]) <= 0, (\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def track_progress(iteration, episode_length):\n",
    "    #clear_output(wait = True)\n",
    "    print(\n",
    "        f'Episode number: {iteration}\\n'\n",
    "        f'Episode length: {episode_length}\\n'\n",
    "    )\n",
    "\n",
    "GAMMA = 0.1\n",
    "EPSILON = 0.1\n",
    "MAX_ITERATIONS = 1000\n",
    "\n",
    "def off_policy_mc_control():\n",
    "    \n",
    "    action_value = {}\n",
    "    normalizing_constant = {}\n",
    "    target_policy = {}  # The target policy is the greedy policy.\n",
    "    \n",
    "    # Used to track progress.\n",
    "    iteration = 1\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        old_action_value = action_value.copy()\n",
    "                \n",
    "        behaviour_policy = epsilon_greedy_policy(target_policy, EPSILON)\n",
    "        \n",
    "        \n",
    "        start_state = random.choice(START_STATES)\n",
    "        episode = run_episode(behaviour_policy, start_state)\n",
    "        episode = list(reversed(episode))\n",
    "        \n",
    "        G = 0.0\n",
    "        W = 1.0\n",
    "        \n",
    "        # Used to track progress.\n",
    "        episode_length = 1\n",
    "        \n",
    "        # Iterate in tuples (t + 1, t)\n",
    "        for (new_state, new_action, new_reward), (state, action, reward) in zip(episode, episode[1:]):\n",
    "            print(\n",
    "                f\"cell_type(new_state): {cell_type(new_state)} \"\n",
    "                f\"cell_type(state): {cell_type(state)} \"\n",
    "                f\"new_state: {new_state} \"\n",
    "                f\"state: {state} \"\n",
    "            )\n",
    "            \n",
    "            G = GAMMA * G + new_reward\n",
    "            \n",
    "            normalizing_constant[(state, action)] = normalizing_constant.get((state, action), 0) + W\n",
    "            \n",
    "            action_value[(state, action)] = (\n",
    "                action_value.get((state, action), 0) +\n",
    "                W / normalizing_constant.get((state, action), 0) * (G - action_value.get((state, action), 0))\n",
    "            )\n",
    "            \n",
    "            target_policy[state] = best_action(state, action_value)\n",
    "            \n",
    "            if action != target_policy[state]:\n",
    "                ipdb.set_trace()\n",
    "                break\n",
    "            \n",
    "            if action == target_policy[state]:\n",
    "                W = W / (1 - EPSILON + EPSILON / len(list(actions(state))))\n",
    "            else:\n",
    "                W = W / (EPSILON / len(list(actions(state))))\n",
    "            \n",
    "            episode_length += 1\n",
    "            \n",
    "            \n",
    "        track_progress(iteration, episode_length)\n",
    "        iteration += 1\n",
    "        \n",
    "        if iteration > MAX_ITERATIONS:\n",
    "            break\n",
    "    \n",
    "    return target_policy, action_value\n",
    "\n",
    "def run_episode(behaviour_policy, start_state):\n",
    "    \"\"\"Used to generate an episode.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize episode at start state, the 0 action, and 0 reward.\n",
    "    state = start_state\n",
    "    episode = [(start_state, 0, 0)]\n",
    "    \n",
    "    while cell_type(state) != 'GOAL':\n",
    "        \n",
    "        action = behaviour_policy(state)\n",
    "        \n",
    "        state = move_car(state, action)\n",
    "        \n",
    "        episode.append(\n",
    "            (state, action, -1)\n",
    "        )\n",
    "        \n",
    "        assert min(action) >= 0 and max(state[2], state[3]) <= 0, (\n",
    "            f'state: {state} '\n",
    "            f'action: {action}'\n",
    "        )\n",
    "        \n",
    "    return episode\n",
    "\n",
    "\n",
    "def epsilon_greedy_policy(target_policy, epsilon = 0.1):\n",
    "    def policy(state):\n",
    "        if random.random() <= epsilon:\n",
    "            return random.choice(list(actions(state)))\n",
    "        return target_policy.get(state, (0, 0))\n",
    "    return policy\n",
    "\n",
    "\n",
    "def best_action(state, action_value):\n",
    "    \"\"\"Returns the best action in a state using the action values.\n",
    "    \"\"\"\n",
    "    state_action_value = [(action_value.get((state, action), -10), action) for action in actions(state)]\n",
    "    best_action = max(state_action_value)[1]\n",
    "    \n",
    "    assert isinstance(best_action, tuple), f'best_action: {best_action}'\n",
    "    return best_action\n",
    "\n",
    "target_policy, action_value = off_policy_mc_control()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state =(4, 1, 1, 1)\n",
    "max(state[2], state[3]) <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "state: (0, 3, 3, 1), list(actions(state)): [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1)], policy(state): (0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2af7f94b4d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     assert max(policy(state)) >= 0, (\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;34mf'state: {state}, list(actions(state)): {list(actions(state))}, policy(state): {policy(state)}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: state: (0, 3, 3, 1), list(actions(state)): [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1)], policy(state): (0, 0)"
     ]
    }
   ],
   "source": [
    "def epsilon_greedy_policy(target_policy, epsilon = 0.1):\n",
    "    def policy(state):\n",
    "        if random.random() <= epsilon:\n",
    "            return random.choice(list(actions(state)))\n",
    "        return target_policy.get(state, (0, 0))\n",
    "    return policy\n",
    "\n",
    "policy = epsilon_greedy_policy({})\n",
    "\n",
    "for state in states():\n",
    "    assert max(policy(state)) >= 0, (\n",
    "        f'state: {state}, list(actions(state)): {list(actions(state))}, policy(state): {policy(state)}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6, 0, 0, 2), (4, 0, 5, 3)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda state: cell_type(state) == 'START', target_policy.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(6, 24, 0, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-4632b38d9c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtarget_policy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtarget_policy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_policy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-252-642103195f66>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(behaviour_policy, start_state)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'GOAL'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehaviour_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmove_car\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-254-4632b38d9c32>\u001b[0m in \u001b[0;36mtarget_policy_\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTART_STATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtarget_policy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtarget_policy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_policy_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (6, 24, 0, 2)"
     ]
    }
   ],
   "source": [
    "start_state = random.choice(START_STATES)\n",
    "def target_policy_(state):\n",
    "    return target_policy[state]\n",
    "run_episode(target_policy_, (6, 0, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 1), (1, 0), (1, 1)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(actions((14, 26, 0, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 14, 3, 1)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, (-1, -1)),\n",
       " (0, (-1, 0)),\n",
       " (0, (-1, 1)),\n",
       " (0, (0, -1)),\n",
       " (0, (0, 0)),\n",
       " (0, (0, 1))]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(action_value.get((state, action), 0), action) for action in actions(state)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "ANIMATE = False\n",
    "\n",
    "start_state = random.choice(START_STATES)\n",
    "def exploring_policy(state):\n",
    "    return random.choice(list(actions(state)))\n",
    "episode = run_episode(exploring_policy, start_state)\n",
    "\n",
    "def reconstruct_last_episode(episode):\n",
    "    \"\"\"Reconstuct a path.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    at_starting_state = False\n",
    "    for state_action_reward in reversed(episode):\n",
    "        state, _, _ = state_action_reward\n",
    "        \n",
    "        if cell_type(state) == 'START':\n",
    "            at_starting_state = True\n",
    "        if at_starting_state and cell_type(state) != 'START':\n",
    "            break\n",
    "        \n",
    "        x, y, dx, dy = state\n",
    "        res.append(\n",
    "            [x, y]\n",
    "        )\n",
    "           \n",
    "    \n",
    "    return list(reversed(res))\n",
    "\n",
    "def plot_walls():\n",
    "    \"\"\"Plot the walls in the map.\n",
    "    \"\"\"\n",
    "    for x, y in set(map(\n",
    "            lambda state: (state[0], state[1]),\n",
    "            filter(\n",
    "                lambda state: cell_type(state) == 'WALL',\n",
    "                list(states())\n",
    "            )\n",
    "        )):\n",
    "        plt.plot([x], [y], marker='o', markersize=3, color=\"black\")\n",
    "\n",
    "last_episode = reconstruct_last_episode(episode)\n",
    "\n",
    "def animate(i, reconstructed_episode = last_episode):\n",
    "    \"\"\"Used to animate the plot.\n",
    "    \"\"\"\n",
    "    [[x1, y1], [x2, y2]] = reconstructed_episode[i:int(i+2)]\n",
    "    \n",
    "    plt.plot([x1,x2],[y1,y2], 'r')\n",
    "    \n",
    "    if cell_type((x2, y2, 0, 0)) == 'GOAL':\n",
    "        plt.plot(x2, y2, '*')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "buffer = 1\n",
    "ax = plt.axes(xlim=(-buffer, MAX_X + buffer), ylim=(-buffer, MAX_Y + buffer))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if ANIMATE:\n",
    "    anim = FuncAnimation(fig, animate,frames=len(last_episode) - 1, interval=300, repeat=False)\n",
    "    HTML(anim.to_html5_video())\n",
    "else:\n",
    "    for i in range(len(last_episode)-1):\n",
    "        animate(i)\n",
    "    \n",
    "plot_walls()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/troels/git/reinforcement_learning_sutton/reinforcement_learning_sutton_project/.venv/lib/python3.7/random.py\u001b[0m(261)\u001b[0;36mchoice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    259 \u001b[0;31m            \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    260 \u001b[0;31m        \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 261 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    262 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    263 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> episode\n",
      "*** NameError: name 'episode' is not defined\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import ipdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import random\n",
    "import ipdb\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "MAP = pd.read_csv('maps/map1.csv', header=None).values\n",
    "CELL_TYPE_MAP = {\n",
    "    0: 'WALL',\n",
    "    1: 'TRACK',\n",
    "    2: 'GOAL',\n",
    "    3: 'START',\n",
    "}\n",
    "\n",
    "# NB: MAP is row, columns, but we want (x, y) which is the reverse.\n",
    "MAX_Y = MAP.shape[0] - 1\n",
    "MAX_X = MAP.shape[1] - 1\n",
    "MAX_VELOCITY = 5\n",
    "EPSILON = 0.1\n",
    "\n",
    "\n",
    "def states():\n",
    "    \"\"\"Generates all possible states.\n",
    "    \"\"\"\n",
    "    for x, y, dx, dy in product(\n",
    "        range(MAX_X + 1), range(MAX_Y + 1), range(0, MAX_VELOCITY + 1), range(0, MAX_VELOCITY + 1)\n",
    "    ):\n",
    "        yield (x, y, dx, dy)\n",
    "\n",
    "\n",
    "def cell_type(state):\n",
    "    \"\"\"Cell types is given by values of CELL_TYPE_MAP.\n",
    "    \"\"\"\n",
    "    x, y, dx, dy = state\n",
    "    \n",
    "    if 0 <= x <= MAX_X and 0 <= y <= MAX_Y:\n",
    "        return CELL_TYPE_MAP[MAP[MAX_Y - y, x]]\n",
    "    \n",
    "    if 0 <= x <= MAX_X + MAX_VELOCITY and 0 <= y <= MAX_Y + MAX_VELOCITY:\n",
    "        return 'WALL'\n",
    "    \n",
    "    raise ValueError(f'Impossible state: {state}.')\n",
    "\n",
    "\n",
    "START_STATES = list(filter(lambda state: cell_type(state) == 'START', states()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0, 0, 0),\n",
       " (3, 0, 0, 1),\n",
       " (3, 0, 0, 2),\n",
       " (3, 0, 0, 3),\n",
       " (3, 0, 0, 4),\n",
       " (3, 0, 0, 5),\n",
       " (3, 0, 1, 0),\n",
       " (3, 0, 1, 1),\n",
       " (3, 0, 1, 2),\n",
       " (3, 0, 1, 3),\n",
       " (3, 0, 1, 4),\n",
       " (3, 0, 1, 5),\n",
       " (3, 0, 2, 0),\n",
       " (3, 0, 2, 1),\n",
       " (3, 0, 2, 2),\n",
       " (3, 0, 2, 3),\n",
       " (3, 0, 2, 4),\n",
       " (3, 0, 2, 5),\n",
       " (3, 0, 3, 0),\n",
       " (3, 0, 3, 1),\n",
       " (3, 0, 3, 2),\n",
       " (3, 0, 3, 3),\n",
       " (3, 0, 3, 4),\n",
       " (3, 0, 3, 5),\n",
       " (3, 0, 4, 0),\n",
       " (3, 0, 4, 1),\n",
       " (3, 0, 4, 2),\n",
       " (3, 0, 4, 3),\n",
       " (3, 0, 4, 4),\n",
       " (3, 0, 4, 5),\n",
       " (3, 0, 5, 0),\n",
       " (3, 0, 5, 1),\n",
       " (3, 0, 5, 2),\n",
       " (3, 0, 5, 3),\n",
       " (3, 0, 5, 4),\n",
       " (3, 0, 5, 5),\n",
       " (4, 0, 0, 0),\n",
       " (4, 0, 0, 1),\n",
       " (4, 0, 0, 2),\n",
       " (4, 0, 0, 3),\n",
       " (4, 0, 0, 4),\n",
       " (4, 0, 0, 5),\n",
       " (4, 0, 1, 0),\n",
       " (4, 0, 1, 1),\n",
       " (4, 0, 1, 2),\n",
       " (4, 0, 1, 3),\n",
       " (4, 0, 1, 4),\n",
       " (4, 0, 1, 5),\n",
       " (4, 0, 2, 0),\n",
       " (4, 0, 2, 1),\n",
       " (4, 0, 2, 2),\n",
       " (4, 0, 2, 3),\n",
       " (4, 0, 2, 4),\n",
       " (4, 0, 2, 5),\n",
       " (4, 0, 3, 0),\n",
       " (4, 0, 3, 1),\n",
       " (4, 0, 3, 2),\n",
       " (4, 0, 3, 3),\n",
       " (4, 0, 3, 4),\n",
       " (4, 0, 3, 5),\n",
       " (4, 0, 4, 0),\n",
       " (4, 0, 4, 1),\n",
       " (4, 0, 4, 2),\n",
       " (4, 0, 4, 3),\n",
       " (4, 0, 4, 4),\n",
       " (4, 0, 4, 5),\n",
       " (4, 0, 5, 0),\n",
       " (4, 0, 5, 1),\n",
       " (4, 0, 5, 2),\n",
       " (4, 0, 5, 3),\n",
       " (4, 0, 5, 4),\n",
       " (4, 0, 5, 5),\n",
       " (5, 0, 0, 0),\n",
       " (5, 0, 0, 1),\n",
       " (5, 0, 0, 2),\n",
       " (5, 0, 0, 3),\n",
       " (5, 0, 0, 4),\n",
       " (5, 0, 0, 5),\n",
       " (5, 0, 1, 0),\n",
       " (5, 0, 1, 1),\n",
       " (5, 0, 1, 2),\n",
       " (5, 0, 1, 3),\n",
       " (5, 0, 1, 4),\n",
       " (5, 0, 1, 5),\n",
       " (5, 0, 2, 0),\n",
       " (5, 0, 2, 1),\n",
       " (5, 0, 2, 2),\n",
       " (5, 0, 2, 3),\n",
       " (5, 0, 2, 4),\n",
       " (5, 0, 2, 5),\n",
       " (5, 0, 3, 0),\n",
       " (5, 0, 3, 1),\n",
       " (5, 0, 3, 2),\n",
       " (5, 0, 3, 3),\n",
       " (5, 0, 3, 4),\n",
       " (5, 0, 3, 5),\n",
       " (5, 0, 4, 0),\n",
       " (5, 0, 4, 1),\n",
       " (5, 0, 4, 2),\n",
       " (5, 0, 4, 3),\n",
       " (5, 0, 4, 4),\n",
       " (5, 0, 4, 5),\n",
       " (5, 0, 5, 0),\n",
       " (5, 0, 5, 1),\n",
       " (5, 0, 5, 2),\n",
       " (5, 0, 5, 3),\n",
       " (5, 0, 5, 4),\n",
       " (5, 0, 5, 5),\n",
       " (6, 0, 0, 0),\n",
       " (6, 0, 0, 1),\n",
       " (6, 0, 0, 2),\n",
       " (6, 0, 0, 3),\n",
       " (6, 0, 0, 4),\n",
       " (6, 0, 0, 5),\n",
       " (6, 0, 1, 0),\n",
       " (6, 0, 1, 1),\n",
       " (6, 0, 1, 2),\n",
       " (6, 0, 1, 3),\n",
       " (6, 0, 1, 4),\n",
       " (6, 0, 1, 5),\n",
       " (6, 0, 2, 0),\n",
       " (6, 0, 2, 1),\n",
       " (6, 0, 2, 2),\n",
       " (6, 0, 2, 3),\n",
       " (6, 0, 2, 4),\n",
       " (6, 0, 2, 5),\n",
       " (6, 0, 3, 0),\n",
       " (6, 0, 3, 1),\n",
       " (6, 0, 3, 2),\n",
       " (6, 0, 3, 3),\n",
       " (6, 0, 3, 4),\n",
       " (6, 0, 3, 5),\n",
       " (6, 0, 4, 0),\n",
       " (6, 0, 4, 1),\n",
       " (6, 0, 4, 2),\n",
       " (6, 0, 4, 3),\n",
       " (6, 0, 4, 4),\n",
       " (6, 0, 4, 5),\n",
       " (6, 0, 5, 0),\n",
       " (6, 0, 5, 1),\n",
       " (6, 0, 5, 2),\n",
       " (6, 0, 5, 3),\n",
       " (6, 0, 5, 4),\n",
       " (6, 0, 5, 5),\n",
       " (7, 0, 0, 0),\n",
       " (7, 0, 0, 1),\n",
       " (7, 0, 0, 2),\n",
       " (7, 0, 0, 3),\n",
       " (7, 0, 0, 4),\n",
       " (7, 0, 0, 5),\n",
       " (7, 0, 1, 0),\n",
       " (7, 0, 1, 1),\n",
       " (7, 0, 1, 2),\n",
       " (7, 0, 1, 3),\n",
       " (7, 0, 1, 4),\n",
       " (7, 0, 1, 5),\n",
       " (7, 0, 2, 0),\n",
       " (7, 0, 2, 1),\n",
       " (7, 0, 2, 2),\n",
       " (7, 0, 2, 3),\n",
       " (7, 0, 2, 4),\n",
       " (7, 0, 2, 5),\n",
       " (7, 0, 3, 0),\n",
       " (7, 0, 3, 1),\n",
       " (7, 0, 3, 2),\n",
       " (7, 0, 3, 3),\n",
       " (7, 0, 3, 4),\n",
       " (7, 0, 3, 5),\n",
       " (7, 0, 4, 0),\n",
       " (7, 0, 4, 1),\n",
       " (7, 0, 4, 2),\n",
       " (7, 0, 4, 3),\n",
       " (7, 0, 4, 4),\n",
       " (7, 0, 4, 5),\n",
       " (7, 0, 5, 0),\n",
       " (7, 0, 5, 1),\n",
       " (7, 0, 5, 2),\n",
       " (7, 0, 5, 3),\n",
       " (7, 0, 5, 4),\n",
       " (7, 0, 5, 5),\n",
       " (8, 0, 0, 0),\n",
       " (8, 0, 0, 1),\n",
       " (8, 0, 0, 2),\n",
       " (8, 0, 0, 3),\n",
       " (8, 0, 0, 4),\n",
       " (8, 0, 0, 5),\n",
       " (8, 0, 1, 0),\n",
       " (8, 0, 1, 1),\n",
       " (8, 0, 1, 2),\n",
       " (8, 0, 1, 3),\n",
       " (8, 0, 1, 4),\n",
       " (8, 0, 1, 5),\n",
       " (8, 0, 2, 0),\n",
       " (8, 0, 2, 1),\n",
       " (8, 0, 2, 2),\n",
       " (8, 0, 2, 3),\n",
       " (8, 0, 2, 4),\n",
       " (8, 0, 2, 5),\n",
       " (8, 0, 3, 0),\n",
       " (8, 0, 3, 1),\n",
       " (8, 0, 3, 2),\n",
       " (8, 0, 3, 3),\n",
       " (8, 0, 3, 4),\n",
       " (8, 0, 3, 5),\n",
       " (8, 0, 4, 0),\n",
       " (8, 0, 4, 1),\n",
       " (8, 0, 4, 2),\n",
       " (8, 0, 4, 3),\n",
       " (8, 0, 4, 4),\n",
       " (8, 0, 4, 5),\n",
       " (8, 0, 5, 0),\n",
       " (8, 0, 5, 1),\n",
       " (8, 0, 5, 2),\n",
       " (8, 0, 5, 3),\n",
       " (8, 0, 5, 4),\n",
       " (8, 0, 5, 5)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "START_STATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actions(state):\n",
    "    \"\"\"Generate all velocity vectors at a given state.\n",
    "    \"\"\"\n",
    "    x, y, dx, dy = state\n",
    "    \n",
    "    for ddx in [-1, 0, 1]:\n",
    "        for ddy in [-1, 0, 1]:\n",
    "            \n",
    "            new_dx = dx + ddx\n",
    "            new_dy = dy + ddy\n",
    "            \n",
    "            new_x = x + new_dx\n",
    "            new_y = y + new_dy\n",
    "            \n",
    "            # Car can't be outside the track\n",
    "            if not (0 <= new_x <= MAX_X and 0 <= new_y <= MAX_Y):\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # Both velocity components are restricted to be positive and less than 5.\n",
    "            if not (0 <= new_dx <= MAX_VELOCITY and 0 <= new_dy <= MAX_VELOCITY):\n",
    "                continue\n",
    "             \n",
    "            yield (ddx, ddy)\n",
    "            \n",
    "\n",
    "def move_car(state, action):\n",
    "    \"\"\"Move a car using the new velocity vector.\n",
    "    \"\"\"\n",
    "    x, y, dx, dy = state\n",
    "    ddx, ddy = action\n",
    "    \n",
    "    new_dx = dx + ddx\n",
    "    new_dy = dy + ddy\n",
    "    \n",
    "    new_x = x + new_dx\n",
    "    new_y = y + new_dy\n",
    "    \n",
    "    new_state = (new_x, new_y, new_dx, new_dy)\n",
    "\n",
    "    if cell_type(new_state) == 'WALL' or len(list(actions(new_state))) == 0:\n",
    "        return random.choice(START_STATES)\n",
    "    return new_state\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for state in states():\n",
    "    \n",
    "    assert len(list(actions(state))) <= 9, f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "    assert cell_type(state) in CELL_TYPE_MAP.values(), f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "    \n",
    "    for action in actions(state):\n",
    "        \n",
    "        new_state = move_car(state, action)\n",
    "        new_x, new_y, new_dx, new_dy = new_state\n",
    "        \n",
    "        assert 0 <= new_x <= MAX_X, f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "        assert 0 <= new_y <= MAX_Y, f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "        \n",
    "        assert 0 <= new_dx <= MAX_VELOCITY, f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "        assert 0 <= new_dy <= MAX_VELOCITY, f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "        \n",
    "        assert cell_type(new_state) in CELL_TYPE_MAP.values(), (\n",
    "            f\"state: {state}, action: {action}, new_state: {new_state}.\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
